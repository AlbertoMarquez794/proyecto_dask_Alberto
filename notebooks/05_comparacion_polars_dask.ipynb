{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación entre Dask y Polars para Procesamiento de Grandes Volúmenes de Datos en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook, vamos a comparar las capacidades de las bibliotecas Dask y Polars para el manejo de grandes volúmenes de datos en Python. Ambas bibliotecas ofrecen operaciones paralelizadas y están diseñadas para manejar grandes datasets de manera eficiente, pero difieren en sus enfoques, APIs y estrategias de optimización.\n",
    "\n",
    "Objetivos\n",
    "\n",
    "\t•\tComprender las diferencias entre Dask y Polars.\n",
    "\t•\tComparar su rendimiento en tareas comunes de procesamiento de datos.\n",
    "\t•\tEvaluar el uso de memoria, velocidad de cómputo y facilidad de uso para cada biblioteca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dask[complete]\n",
    "# !pip install polars\n",
    "# !pip install \"dask[distributed]\" --upgrade    # or pip install\n",
    "# !pip install \"dask[dataframe]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración\n",
    "\n",
    "Instalación de Bibliotecas Requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un cluster local con múltiples workers y threads\n",
    "cluster = LocalCluster(n_workers=4, threads_per_worker=2, dashboard_address = '8880')  # 4 workers, cada uno con 2 threads\n",
    "client = Client(cluster)\n",
    "\n",
    "# Mostrar el dashboard de Dask para monitoreo (si es necesario)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medir el tiempo de carga del dataset\n",
    "start = time.time()\n",
    "\n",
    "# Cargar el dataset usando Dask (ajusta la cantidad de particiones si es necesario)\n",
    "dask_df = dd.read_csv(\n",
    "    'data/large_dataset.csv',\n",
    "    blocksize=\"64MB\"  # Ajusta el tamaño de cada partición\n",
    ")\n",
    "\n",
    "# Puedes cambiar el blocksize segun tu memoria RAM\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Tiempo de carga con Dask (con cluster): {end - start:.2f} segundos\")\n",
    "\n",
    "# Mostrar las primeras 5 filas del DataFrame\n",
    "print(\"Primeras 5 filas del DataFrame de Dask:\")\n",
    "print(dask_df.head(5))  # `head()` ejecuta las operaciones necesarias para mostrar estas filas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "polars_df = pl.read_csv('data/large_dataset.csv')\n",
    "end = time.time()\n",
    "print(f\"Tiempo de carga con Polars: {end - start:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de Procesamiento de Datos\n",
    "\n",
    "Vamos a realizar algunas tareas comunes de procesamiento de datos para comparar el rendimiento de Dask y Polars. Realizaremos operaciones como filtrado, agregación y agrupación en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 1: Filtrado de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# FILTRADO CON DASK\n",
    "# ===============================\n",
    "\n",
    "# Persistir el DataFrame en memoria distribuida (evita recalcular particiones)\n",
    "dask_df = dask_df.persist()  \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Realizar el filtrado\n",
    "filtered_dask_df = dask_df[dask_df['value1'] > 0.5]  # Operación diferida\n",
    "filtered_result = filtered_dask_df.compute()  # Forzar la ejecución y traer el resultado\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Tiempo de filtrado con Dask (optimizado): {end - start:.2f} segundos\")\n",
    "\n",
    "# ===============================\n",
    "# FILTRADO CON Polars\n",
    "# ===============================\n",
    "\n",
    "start = time.time()\n",
    "filtered_polars_df = polars_df.filter(pl.col('value1') > 0.5)\n",
    "end = time.time()\n",
    "print(f\"Tiempo de filtrado con Polars: {end - start:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Agrupación y Agregación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por 'id' módulo 10 y calcular el promedio de 'value1'\n",
    "start = time.time()\n",
    "agg_dask_df = dask_df.groupby(dask_df['id'] % 10).value1.mean().compute()\n",
    "end = time.time()\n",
    "print(f\"Tiempo de agregación por grupo con Dask: {end - start:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por 'id' módulo 10 y calcular el promedio de 'value1'\n",
    "start = time.time()\n",
    "agg_polars_df = (\n",
    "    polars_df\n",
    "    .with_columns((pl.col(\"id\") % 10).alias(\"grupo_id\"))  # Agregar la columna 'grupo_id'\n",
    "    .group_by(\"grupo_id\")  # Agrupar por 'grupo_id'\n",
    "    .agg(pl.col(\"value1\").mean().alias(\"mean_value1\"))  # Calcular el promedio de 'value1' en cada grupo\n",
    ")\n",
    "end = time.time()\n",
    "\n",
    "# Imprimir el tiempo de ejecución y el resultado\n",
    "print(f\"Tiempo de agregación por grupo con Polars: {end - start:.2f} segundos\")\n",
    "print(agg_polars_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Operación de Unión (Join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame más pequeño para unir con el dataset principal\n",
    "small_dask_df = dask_df.head(1000)\n",
    "\n",
    "# Realizar la operación de unión\n",
    "start = time.time()\n",
    "joined_dask_df = dask_df.merge(small_dask_df, on='id', how='inner').compute()\n",
    "end = time.time()\n",
    "print(f\"Tiempo de unión con Dask: {end - start:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame más pequeño para unir con el dataset principal\n",
    "small_polars_df = polars_df.head(1000)\n",
    "\n",
    "# Realizar la operación de unión\n",
    "start = time.time()\n",
    "joined_polars_df = polars_df.join(small_polars_df, on='id', how='inner')\n",
    "end = time.time()\n",
    "print(f\"Tiempo de unión con Polars: {end - start:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Por qué las operaciones de Dask fueron más lentas que las de Polars?\n",
    "\n",
    "Cuando comparamos Dask y Polars en operaciones como filtrado, agrupación y agregación en un entorno de una sola máquina, es común observar que **Polars es más rápido que Dask**. A continuación, explicamos las razones principales de esta diferencia en rendimiento.\n",
    "\n",
    "## 1. Implementación en Lenguaje de Bajo Nivel\n",
    "\n",
    "- **Polars** está implementado en **Rust**, un lenguaje de bajo nivel que permite manejar la memoria y los recursos de la CPU de manera más eficiente que Python.\n",
    "- Rust optimiza operaciones como el acceso a memoria y el procesamiento de datos en bloques, lo cual es especialmente beneficioso en operaciones de alta concurrencia y uso intensivo de CPU.\n",
    "- **Dask**, en cambio, está escrito en Python, un lenguaje interpretado y de más alto nivel que tiene algunas limitaciones en cuanto a eficiencia de procesamiento, especialmente en tareas que requieren un manejo muy optimizado de memoria y CPU.\n",
    "\n",
    "## 2. Diferencias en el Modelo de Ejecución\n",
    "\n",
    "- **Dask** utiliza un modelo de ejecución **diferida**, donde las operaciones no se ejecutan inmediatamente. En lugar de eso, Dask construye un **gráfico de tareas** (task graph) que organiza las operaciones en un flujo de trabajo optimizado, especialmente útil para entornos distribuidos.\n",
    "  - Esto implica una **sobrecarga de planificación** que, aunque es útil en operaciones complejas o distribuidas, introduce un retraso adicional en tareas simples en una sola máquina.\n",
    "- **Polars** puede ejecutar las operaciones de manera **inmediata** en memoria (sin planificación diferida), lo cual permite que las operaciones se ejecuten más rápidamente en situaciones donde la planificación extra de Dask no es necesaria.\n",
    "\n",
    "## 3. Estructura de Datos Columnares en Polars\n",
    "\n",
    "- Polars utiliza una **estructura de datos columnares** (similar a Apache Arrow) que está optimizada para operaciones como selección de columnas y filtrado.\n",
    "- Esta estructura permite a Polars trabajar con datos en bloques de memoria continuos y realizar operaciones columnares de forma muy rápida, ya que no necesita acceder a datos de otras columnas o filas.\n",
    "- **Dask**, por otro lado, está basado en la estructura de datos de pandas, que está orientada a filas y no está optimizada de la misma manera para operaciones columnares rápidas.\n",
    "\n",
    "## 4. Menor Necesidad de Manejo de Particiones en Polars\n",
    "\n",
    "- **Dask** divide el DataFrame en **múltiples particiones** para procesarlas en paralelo. Este enfoque es ideal para datasets que no caben en memoria, ya que permite dividir el trabajo entre varias máquinas o núcleos de CPU.\n",
    "  - Sin embargo, en operaciones simples, el manejo de particiones añade una sobrecarga. Dask necesita combinar los resultados de cada partición después de realizar la operación, lo cual puede ralentizar el proceso.\n",
    "- **Polars** trabaja en un solo bloque de datos en memoria (si el dataset cabe en memoria), lo cual evita la sobrecarga de manejar particiones y resulta en operaciones más rápidas en datasets de tamaño moderado que caben en la memoria de una sola máquina.\n",
    "\n",
    "## 5. Uso de SIMD y Paralelismo Interno en Polars\n",
    "\n",
    "- **Polars** está diseñado para aprovechar instrucciones **SIMD (Single Instruction, Multiple Data)**, que permiten procesar múltiples elementos en paralelo a nivel de CPU, optimizando así operaciones como el filtrado y la agregación.\n",
    "- **Dask** paraleliza tareas al nivel de particiones y usa múltiples hilos de Python. Sin embargo, su paralelismo está limitado por el **Global Interpreter Lock (GIL)** de Python, lo que puede reducir el rendimiento en comparación con el procesamiento paralelo optimizado de Polars en Rust.\n",
    "\n",
    "## 6. Diferentes Casos de Uso\n",
    "\n",
    "- **Dask** es ideal para entornos distribuidos o cuando se trabaja con datasets que no caben en memoria, ya que permite procesar datos en múltiples máquinas o núcleos de CPU.\n",
    "- **Polars** está optimizado para cargas de trabajo en una sola máquina y es extremadamente eficiente en operaciones en memoria cuando el dataset cabe en la RAM de la máquina.\n",
    "- En casos de uso de **big data distribuido**, Dask puede ser más eficiente que Polars debido a su capacidad de escalar horizontalmente, mientras que en operaciones en una sola máquina, Polars suele tener un mejor rendimiento.\n",
    "\n",
    "\n",
    "**Dask** es excelente para procesamiento distribuido y escalabilidad en entornos donde el dataset es demasiado grande para caber en la memoria de una sola máquina, mientras que **Polars** es ideal para procesamiento rápido en memoria en una máquina única."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos donde Dask es Mejor que Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRER ESTE EN SU PROPIA MAQUINA\n",
    "\n",
    "# Definir el tamaño del archivo y la cantidad de filas\n",
    "num_rows = 100_000_000  # Aproximadamente 50 GB\n",
    "chunk_size = 10_000_000  # Tamaño de cada chunk (10 millones de filas)\n",
    "\n",
    "# Columnas del DataFrame\n",
    "columns = ['id', 'category', 'value1', 'value2']\n",
    "\n",
    "# Especificar la carpeta y el nombre del archivo\n",
    "output_folder = \"data\"  # Carpeta donde guardar el archivo\n",
    "output_file = \"large_dataset_2.csv\"\n",
    "\n",
    "# Crear la carpeta si no existe\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Ruta completa al archivo\n",
    "output_path = os.path.join(output_folder, output_file)\n",
    "\n",
    "# Crear el archivo CSV en chunks\n",
    "for i in range(0, num_rows, chunk_size):\n",
    "    # Crear un chunk de datos\n",
    "    df = pd.DataFrame({\n",
    "        'id': np.arange(i, i + chunk_size),\n",
    "        'category': np.random.choice(['A', 'B', 'C', 'D'], size=chunk_size),\n",
    "        'value1': np.random.rand(chunk_size),\n",
    "        'value2': np.random.rand(chunk_size)\n",
    "    })\n",
    "\n",
    "    # Guardar el chunk en el archivo CSV (modo append después del primer chunk)\n",
    "    if i == 0:\n",
    "        # Si es el primer chunk, escribe con encabezado\n",
    "        df.to_csv(output_path, index=False)\n",
    "    else:\n",
    "        # Si no es el primer chunk, añade al archivo sin encabezado\n",
    "        df.to_csv(output_path, mode='a', header=False, index=False)\n",
    "\n",
    "    # Imprimir progreso\n",
    "    print(f\"Chunk {i // chunk_size + 1} guardado ({i + chunk_size}/{num_rows} filas procesadas)\")\n",
    "\n",
    "print(f\"Archivo CSV grande generado como: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectarte al cluster existente\n",
    "client = Client()  # Ya habías configurado el cluster antes\n",
    "print(client)\n",
    "\n",
    "# Medir el tiempo de carga del dataset\n",
    "start = time.time()\n",
    "\n",
    "# Cargar el dataset usando Dask (ajusta la cantidad de particiones si es necesario)\n",
    "dask_df2 = dd.read_csv(\n",
    "    'data/large_dataset_2.csv',\n",
    "    blocksize=\"64MB\"  # Ajusta el tamaño de cada partición\n",
    ")\n",
    "\n",
    "# Puedes cambiar el blocksize segun tu memoria RAM\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Tiempo de carga con Dask (con cluster): {end - start:.2f} segundos\")\n",
    "\n",
    "# Mostrar las primeras 5 filas del DataFrame\n",
    "print(\"Primeras 5 filas del DataFrame de Dask:\")\n",
    "print(dask_df2.head(5))  # `head()` ejecuta las operaciones necesarias para mostrar estas filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "polars_df2 = pl.read_csv('data/large_dataset_2.csv')\n",
    "end = time.time()\n",
    "print(f\"Tiempo de carga con Polars: {end - start:.2f} segundos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
