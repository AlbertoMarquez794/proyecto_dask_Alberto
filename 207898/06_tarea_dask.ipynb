{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Instrucciones generales\n",
    "- Esta tarea debe realizarse de manera individual\n",
    "- Este notebook (resuelto) debe ser subido al github del proyecto en la carpeta de tareas (creen una carpeta dentro de esa carpeta y agreguen su notebook reuelto)\n",
    "- Fecha límite: Lunes 25 de noviembre de 2024 a las 11:59 p.m\n",
    "- Deben realizar las cuatro secciones\n",
    "- Puedes agregar tantas celdas de código y explicaciones como veas necesario, solo manten la estructura general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 0 Creación y Configuración del cliente de Dask\n",
    "Ejercicio 0: Configuración del cliente\n",
    "1. Crea un cliente local de Dask que inicie un clúster en tu máquina.\n",
    "2. Configura el cliente para que tenga las siguientes características (elige un par de las opciones de trabajadores e hilos):\n",
    "    - Número de trabajadores: 2 / 4\n",
    "    - Memoria máxima por trabajador: 1GB\n",
    "    - Threads por trabajador: 4 / 2\n",
    "3. Verifica que el cliente esté funcionando correctamente mostrando:\n",
    "    - Resumen de los trabajadores activos.\n",
    "    - Dashboard disponible (URL del panel de control de Dask).\n",
    "    * Tip: Checa los parámetros del cliente que creeaste.\n",
    "\n",
    "*Nota*: Puedes hacer que corra en el puerto que desees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Tu código va aquí\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m      4\u001b[0m client \u001b[38;5;241m=\u001b[39m Client(\n\u001b[1;32m      5\u001b[0m     n_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \n\u001b[1;32m      6\u001b[0m     threads_per_worker\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m      7\u001b[0m     memory_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1GB\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dask'"
     ]
    }
   ],
   "source": [
    "# Tu código va aquí\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\n",
    "    n_workers = 2, \n",
    "    threads_per_worker=4,\n",
    "    memory_limit='1GB',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Sección 1 Delayed\n",
    "Ejercicio 1: Procesamiento de datos \n",
    "\n",
    "1. Genera datos simulados (por ejemplo, ventas diarias) para 10 sucursales durante 365 días.\n",
    "    - Cada sucursal debe tener datos generados aleatoriamente para \"Ingresos\" y \"Costos\".\n",
    "    - Utiliza una función para generar los datos simulados.\n",
    "2. Usa Dask Delayed para calcular:\n",
    "    - Las ganancias diarias por sucursal.\n",
    "    - La sucursal con mayor ganancia promedio.\n",
    "3. Genera un grafo de tareas que visualice estas operaciones y explica por qué elegiste paralelizar de esa forma, genera una visualización del grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dask import delayed\n",
    "from dask import visualize\n",
    "# Paso 1: Generar datos simulados\n",
    "def generar_datos_sucursal(sucursal_id):\n",
    "    fechas = pd.date_range(start='2022-01-01', periods=365, freq='D')\n",
    "    ingresos = np.random.uniform(1000, 5000, size=365)\n",
    "    costos = np.random.uniform(500, 3000, size=365)\n",
    "    datos = pd.DataFrame({\n",
    "        'Fecha': fechas,\n",
    "        'Sucursal': sucursal_id,\n",
    "        'Ingresos': ingresos,\n",
    "        'Costos': costos\n",
    "    })\n",
    "    return datos\n",
    "\n",
    "# Generar datos para 10 sucursales\n",
    "sucursales = []\n",
    "for i in range(1, 11):\n",
    "    sucursal_datos = generar_datos_sucursal(f'Sucursal_{i}')\n",
    "    sucursales.append(sucursal_datos)\n",
    "\n",
    "# Concatenar datos de todas las sucursales\n",
    "datos_totales = pd.concat(sucursales, ignore_index=True)\n",
    "print(datos_totales)\n",
    "\n",
    "\n",
    "# Paso 2: Calcular ganancias diarias por sucursal usando Dask Delayed\n",
    "@delayed\n",
    "def calcular_ganancia_diaria(datos_sucursal):\n",
    "    datos_sucursal['Ganancia'] = datos_sucursal['Ingresos'] - datos_sucursal['Costos']\n",
    "    return datos_sucursal\n",
    "\n",
    "# Aplicar la función retrasada a cada sucursal\n",
    "tareas_ganancia = []\n",
    "for sucursal_id in datos_totales['Sucursal'].unique():\n",
    "    datos_sucursal = datos_totales[datos_totales['Sucursal'] == sucursal_id]\n",
    "    tarea = calcular_ganancia_diaria(datos_sucursal)\n",
    "    tareas_ganancia.append(tarea)\n",
    "\n",
    "# Paso 3: Calcular la ganancia promedio por sucursal\n",
    "@delayed\n",
    "def calcular_ganancia_promedio(datos_sucursal):\n",
    "    ganancia_promedio = datos_sucursal['Ganancia'].mean()\n",
    "    return (datos_sucursal['Sucursal'].iloc[0], ganancia_promedio)\n",
    "\n",
    "# Aplicar la función retrasada para calcular la ganancia promedio\n",
    "tareas_ganancia_promedio = [calcular_ganancia_promedio(tarea) for tarea in tareas_ganancia]\n",
    "\n",
    "# Encontrar la sucursal con mayor ganancia promedio\n",
    "@delayed\n",
    "def sucursal_mayor_ganancia(lista_ganancias):\n",
    "    return max(lista_ganancias, key=lambda x: x[1])\n",
    "\n",
    "tarea_mayor_ganancia = sucursal_mayor_ganancia(tareas_ganancia_promedio)\n",
    "\n",
    "# Paso 4: Generar y visualizar el grafo de tareas\n",
    "# Visualizar el grafo de tareas (el archivo se guardará como 'grafo_tareas.png')\n",
    "tarea_mayor_ganancia.visualize()\n",
    "# Paso 5: Ejecutar las tareas y obtener el resultado\n",
    "resultado = tarea_mayor_ganancia.compute()\n",
    "print(f\"La sucursal con mayor ganancia promedio es {resultado[0]} con una ganancia promedio de {resultado[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 2 Dask Dataframes\n",
    "Ejercicio 2: Limpieza y análisis de datos reales\n",
    "\n",
    "1. Descarga un conjunto de datos masivo (puedes usar la colección de *nycflights* que se encuentra en `data/nycflights/`).\n",
    "2. Carga los datos en un Dask DataFrame. \n",
    "    - Elige adecuadamente el número de particiones (que quepan en memoria de los `workers`)\n",
    "3. Realiza las siguientes tareas:\n",
    "    - Limpia los valores faltantes en las columnas `ArrDelay` y `DepDelay`, rellenándolos con la mediana de cada columna.\n",
    "    - Calcula el retraso promedio (`DepDelay`) por mes y aerolínea.\n",
    "    - Encuentra el aeropuerto de origen con más vuelos retrasados.\n",
    "\n",
    "*Nota*: **Evita** convertir el DataFrame a pandas e **intenta** realizar `.compute()` solo cuando sea necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código va aquí\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Cargar el archivo CSV en un Dask DataFrame\n",
    "# Ajusta la ruta si es necesario según la ubicación de los datos\n",
    "ruta_archivo = 'data/nycflights/*.csv'  # Ruta que contiene múltiples archivos CSV de nycflights\n",
    "df = dd.read_csv(ruta_archivo, dtype = dtype)\n",
    "\n",
    "# Dividir en un número adecuado de particiones (dependerá de la memoria disponible)\n",
    "# En este caso, se elige dividir en 10 particiones, pero puedes ajustar según tu máquina\n",
    "df = df.repartition(npartitions=10)\n",
    "\n",
    "mediana_ArrDelay = df[\"ArrDelay\"].median_approximate()\n",
    "if(df[\"ArrDelay\"].isna):\n",
    "    df[\"ArrDelay\"].apply(\n",
    "    lambda x: mediana_ArrDelay, meta=('x','float')\n",
    "    )\n",
    "mediana_DepDelay = df[\"DepDelay\"].median_approximate()\n",
    "if(df[\"DepDelay\"].isna):\n",
    "    df[\"DepDelay\"].apply(\n",
    "    lambda x: mediana_DepDelay, meta=('x','float')\n",
    "    )\n",
    "delay_by_month_airline = df.groupby(['Month', 'UniqueCarrier'])['DepDelay'].mean()\n",
    "delayed_flights = df[df['DepDelay'] > 0]\n",
    "origin_with_most_delays = delayed_flights['Origin'].value_counts().idxmax().compute()\n",
    "\n",
    "print(\"Retraso promedio por mes y aerolínea:\")\n",
    "print(delay_by_month_airline.compute())\n",
    "\n",
    "print(\"\\nAeropuerto de origen con más vuelos retrasados:\")\n",
    "print(origin_with_most_delays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 3 Dask Arrays\n",
    "\n",
    "Ejercicio 3: Procesamiento numérico avanzado\n",
    "\n",
    "1. Crea un arreglo de 10,000 x 10,000 con valores aleatorios usando Dask Array, utiliza un tamaño de chunks adecuado, ¿es mejor que sean cuadrados?.\n",
    "2. Realiza las siguientes operaciones:\n",
    "    - Calcula la suma de cada fila.\n",
    "    - Encuentra la fila con el valor máximo promedio.\n",
    "    - Multiplica todo el arreglo por un factor escalar (por ejemplo, 2.5).\n",
    "3. Divide el arreglo nuevamente en 100 bloques y compara la rapidez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código va aquí\n",
    "import dask.array as da\n",
    "import time\n",
    "\n",
    "# Definir el tamaño del arreglo\n",
    "shape = (10000, 10000)\n",
    "\n",
    "# Crear arreglos Dask con diferentes tamaños de chunks\n",
    "arr_cuadrado = da.random.random(size=shape, chunks=(1000, 1000))\n",
    "arr_filas = da.random.random(size=shape, chunks=(10000, 1000))\n",
    "arr_columnas = da.random.random(size=shape, chunks=(1000, 10000))\n",
    "\n",
    "def realizar_operaciones(arr):\n",
    "    inicio = time.time()\n",
    "    \n",
    "    # Calcular la suma de cada fila\n",
    "    sumas_filas = arr.sum(axis=1)\n",
    "    sumas_filas_resultado = sumas_filas.compute()\n",
    "    \n",
    "    # Encontrar la fila con el valor máximo promedio\n",
    "    promedios_filas = arr.mean(axis=1)\n",
    "    indice_max_promedio = promedios_filas.argmax()\n",
    "    indice_max_promedio_resultado = indice_max_promedio.compute()\n",
    "    \n",
    "    # Multiplicar todo el arreglo por un factor escalar (2.5)\n",
    "    arr_escalado = arr * 2.5\n",
    "    arr_escalado_resultado = arr_escalado.compute()\n",
    "    \n",
    "    fin = time.time()\n",
    "    tiempo_total = fin - inicio\n",
    "    \n",
    "    return tiempo_total, indice_max_promedio_resultado\n",
    "\n",
    "# Operaciones con chunks cuadrados\n",
    "tiempo_cuadrado, indice_max_cuadrado = realizar_operaciones(arr_cuadrado)\n",
    "print(f\"Tiempo con chunks cuadrados (1000, 1000): {tiempo_cuadrado:.2f} segundos\")\n",
    "print(f\"Fila con el promedio máximo: {indice_max_cuadrado}\")\n",
    "\n",
    "# Operaciones con chunks grandes en filas\n",
    "tiempo_filas, indice_max_filas = realizar_operaciones(arr_filas)\n",
    "print(f\"Tiempo con chunks en filas (10000, 1000): {tiempo_filas:.2f} segundos\")\n",
    "print(f\"Fila con el promedio máximo: {indice_max_filas}\")\n",
    "\n",
    "# Operaciones con chunks grandes en columnas\n",
    "tiempo_columnas, indice_max_columnas = realizar_operaciones(arr_columnas)\n",
    "print(f\"Tiempo con chunks en columnas (1000, 10000): {tiempo_columnas:.2f} segundos\")\n",
    "print(f\"Fila con el promedio máximo: {indice_max_columnas}\")\n",
    "\n",
    "# Rechunking a 100 bloques y comparación\n",
    "arr_rechunk = arr_cuadrado.rechunk((1000, 1000))\n",
    "tiempo_rechunk, indice_max_rechunk = realizar_operaciones(arr_rechunk)\n",
    "print(f\"Tiempo después de rechunking (1000, 1000): {tiempo_rechunk:.2f} segundos\")\n",
    "print(f\"Fila con el promedio máximo: {indice_max_rechunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 4 Futures\n",
    "Ejercicio 4: Distribución de tareas dinámicas\n",
    "\n",
    "1. Implementa una función que calcule la raíz cuadrada de una lista de 100,000 números enteros generados aleatoriamente.\n",
    "2. Divide la lista en 10 partes iguales y usa Dask Futures para calcular la raíz cuadrada de cada parte en paralelo.\n",
    "3. Recolecta los resultados y calcula:\n",
    "    - El promedio de todos los números procesados.\n",
    "    - El tiempo total de ejecución (incluyendo envío y recolección de tareas).\n",
    "4. Observa como se distribuye la carga en el cliente.\n",
    "\n",
    "*Nota*: en los ejercicios ya vimos como determinar si ya se cumplío una tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código va aquí\n",
    "# Tu código va aquí\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Inicializar el cliente Dask\n",
    "client = Client()\n",
    "\n",
    "def compute_sqrt(numbers):\n",
    "    \"\"\"Función que calcula la raíz cuadrada de una lista de números.\"\"\"\n",
    "    return np.sqrt(numbers)\n",
    "\n",
    "# Generar la lista de 100,000 números enteros aleatorios\n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "numbers = np.random.randint(1, 1000000, size=100000)\n",
    "\n",
    "# Dividir la lista en 10 partes iguales\n",
    "partitions = np.array_split(numbers, 10)\n",
    "\n",
    "# Medir el tiempo total de ejecución\n",
    "start_time = time.time()\n",
    "\n",
    "# Enviar tareas al cluster usando Dask Futures\n",
    "futures = [client.submit(compute_sqrt, part) for part in partitions]\n",
    "\n",
    "# Recolectar los resultados\n",
    "results = client.gather(futures)\n",
    "\n",
    "# Calcular el promedio de todos los números procesados\n",
    "all_results = np.concatenate(results)\n",
    "average_result = np.mean(all_results)\n",
    "\n",
    "# Tiempo total de ejecución\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Promedio de los números procesados: {average_result}\")\n",
    "print(f\"Tiempo total de ejecución: {total_time:.2f} segundos\")\n",
    "\n",
    "# Mostrar el cliente Dask\n",
    "print(\"\\nDistribución de carga:\")\n",
    "print(client)\n",
    "\n",
    "# Cerrar el cliente\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
